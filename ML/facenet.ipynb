{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.applications import resnet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle\n",
    "import numpy.random as rng\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "anchor=Input((120,120,3))\n",
    "positive=Input((120,120,3))\n",
    "negetive=Input((120,120,3))\n",
    "convnet = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(120,120,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in convnet.layers[:-1]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def  __init__(self,alpha,**kwargs):\n",
    "        self.alpha=alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        anchor, positive, negative = inputs\n",
    "        p_dist = K.sum(K.square(anchor-positive), axis=-1)\n",
    "        n_dist = K.sum(K.square(anchor-negative), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = convnet.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024,kernel_regularizer=l2(2e-3))(x)\n",
    "convnet = Model(inputs=convnet.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_a = convnet(anchor)\n",
    "encoded_p = convnet(positive)\n",
    "encoded_n = convnet(negetive)\n",
    "\n",
    "Euc_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "\n",
    "loss_layer=TripletLossLayer(alpha=0.2,name=\"triplet_loss_layer\")([encoded_a,encoded_p,encoded_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[anchor,positive,negetive],outputs=loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1024)         57143168    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "triplet_loss_layer (TripletLoss [(None, 1024), (None 0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,143,168\n",
      "Trainable params: 33,555,456\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py:819: UserWarning: Output triplet_loss_layer missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to triplet_loss_layer.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.00006)\n",
    "model.compile(loss=None,optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "curr_y=0\n",
    "n_dict={}\n",
    "root='./PINS'\n",
    "for name in os.listdir(root):\n",
    "    n_dict[name.split(\"_\")[1]]=curr_y\n",
    "    curr_y+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron Paul\n",
      "alexandra daddario\n",
      "Alvaro Morte\n",
      "alycia debnam carey face\n",
      "Amanda Crew\n",
      "Amaury Nolasco\n",
      "amber heard face\n",
      "Anna Gunn\n",
      "anne hathaway\n",
      "barbara palvin face\n",
      "bellamy blake face\n",
      "Benedict Cumberbatch\n",
      "Betsy Brandt\n",
      "bill gates\n",
      "Brenton Thwaites\n",
      "brie larson\n",
      "Brit Marling\n",
      "Bryan Cranston\n",
      "Caity Lotz\n",
      "Cameron Monaghan\n",
      "chadwick boseman face\n",
      "Chance Perdomo\n",
      "Chris Evans\n",
      "Chris Pratt\n",
      "Cobie Smulders\n",
      "Danielle Panabaker\n",
      "Dave Franco\n",
      "david mazouz\n",
      "Dominic Purcell\n",
      "drake\n",
      "dua lipa face\n",
      "Dwayne Johnson\n",
      "eliza taylor\n",
      "elizabeth olsen face\n",
      "elon musk\n",
      "Emilia Clarke\n",
      "Emily Bett Rickards\n",
      "Emma Stone\n",
      "emma watson face\n",
      "gal gadot face\n",
      "grant gustin face\n",
      "Gwyneth Paltrow\n",
      "Henry Cavil\n",
      "jason isaacs\n",
      "Jason Momoa\n",
      "jeff bezos\n",
      "Jeremy Renner\n",
      "Jesse Eisenberg\n",
      "Jim Parsons\n",
      "Jon Bernthal\n",
      "Josh Radnor\n",
      "kiernan shipka\n",
      "Kit Harington\n",
      "kristen stewart face\n",
      "Krysten Ritter\n",
      "Kumail Nanjiani\n",
      "lindsey morgan face\n",
      "Maisie Williams\n",
      "margot robbie face\n",
      "maria pedraza\n",
      "Mark Ruffalo\n",
      "mark zuckerberg\n",
      "Martin Starr\n",
      "Melissa benoit\n",
      "miguel herran\n",
      "Mike Colter\n",
      "millie bobby brown\n",
      "Morena Baccarin\n",
      "Morgan Freeman\n",
      "Natalie Portman\n",
      "Neil Patrick Harris\n",
      "Paul Rudd\n",
      "Pedro Alonso\n",
      "Peter Dinklage\n",
      "Rami Melek\n",
      "rihanna\n",
      "RJ Mitte\n",
      "robert downey jr face\n",
      "Robert Knepper\n",
      "Robin Taylor\n",
      "Ryan Reynolds\n",
      "Sarah Wayne Callies\n",
      "Scarlett Johansson\n",
      "sean pertwee\n",
      "Sebastian Stan\n",
      "selena gomez\n",
      "shakira\n",
      "Sophie Turner\n",
      "Stephen Amell\n",
      "Sundar Pichai\n",
      "tati gabrielle\n",
      "taylor swift\n",
      "Thomas Middleditch\n",
      "Tom Cavanagh\n",
      "tom holland face\n",
      "Ursula Corbero\n",
      "Wentworth Miller\n",
      "Willa Holland\n",
      "William Fichtner\n",
      "zendaya\n"
     ]
    }
   ],
   "source": [
    "root='./PINS'\n",
    "root\n",
    "for name in os.listdir(root):\n",
    "    namepath=os.path.join(root,name)\n",
    "    p_name=name.split(\"_\")[1]\n",
    "    print(p_name)\n",
    "    for image in os.listdir(namepath):\n",
    "        image_path=os.path.join(namepath,image)\n",
    "        new_image=Image.open(image_path)\n",
    "        size=(120,120)\n",
    "        new_image=new_image.resize(size,Image.ANTIALIAS)\n",
    "        final_image=np.array(new_image,'uint8')/255.0\n",
    "        ##print(final_image.shape)\n",
    "        shape=final_image.shape\n",
    "        final_image=final_image.reshape(shape[0],shape[1],3)\n",
    "        X.append(np.stack(final_image))\n",
    "        y.append(n_dict[p_name])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.32670483,  0.5797118 ,  0.1586476 , ...,  0.26011398,\n",
       "         0.42816803, -0.03649538]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_img = convnet.predict(np.ones((1,120,120,3)))\n",
    "featured_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=[]\n",
    " \n",
    "for n in range(100):\n",
    "    images_class_n=np.asarray([row for idx,row in enumerate(X) if y[idx]==n])\n",
    "    dataset_train.append(images_class_n/255)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_train[0].shape\n",
    "print((dataset_train[5].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_random(batch_size,s=\"train\"):\n",
    "    \n",
    "    if s==\"train\":\n",
    "        X=dataset_train\n",
    "        nb_classes=len(dataset_train)\n",
    "    else:\n",
    "        X=dataset_test\n",
    "        nb_classes=(len(dataset_test))\n",
    "    m,w,h,c=X[0].shape\n",
    "    \n",
    "    triplets=[np.zeros((batch_size,h,w,c)) for i in range(3)]\n",
    "    \n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        anchor_class=np.random.randint(0,nb_classes)\n",
    "        nb_sample_available_for_class_AP=X[anchor_class].shape[0]\n",
    "        \n",
    "        [idx_A,idx_P]=np.random.choice(nb_sample_available_for_class_AP,size=2,replace=False)\n",
    "        \n",
    "        negative_class = (anchor_class + np.random.randint(1,nb_classes)) % nb_classes\n",
    "        nb_sample_available_for_class_N = X[negative_class].shape[0]\n",
    "        \n",
    "        idx_N = np.random.randint(0, nb_sample_available_for_class_N)\n",
    "        \n",
    "        triplets[0][i,:,:,:] = X[anchor_class][idx_A,:,:,:]\n",
    "        triplets[1][i,:,:,:] = X[anchor_class][idx_P,:,:,:]\n",
    "        triplets[2][i,:,:,:] = X[negative_class][idx_N,:,:,:]\n",
    "        \n",
    "    return triplets\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.sum(np.square(a-b))\n",
    "\n",
    "def get_batch_hard(draw_batch_size,hard_batchs_size,norm_batchs_size,network,s=\"train\"):\n",
    "    \n",
    "    if s == 'train':\n",
    "        X = dataset_train\n",
    "    else:\n",
    "        X = dataset_test\n",
    "\n",
    "    m, w, h,c = X[0].shape  \n",
    "    \n",
    "    studybatch = get_batch_random(draw_batch_size,s)\n",
    "        \n",
    "    studybatchloss = np.zeros((draw_batch_size))\n",
    "    \n",
    "    A = network.predict(studybatch[0])\n",
    "    P = network.predict(studybatch[1])\n",
    "    N = network.predict(studybatch[2])\n",
    "\n",
    "    studybatchloss = np.sum(np.square(A-P),axis=1) - np.sum(np.square(A-N),axis=1)\n",
    "    \n",
    "    selection = np.argsort(studybatchloss)[::-1][:hard_batchs_size]\n",
    "    \n",
    "    selection2 = np.random.choice(np.delete(np.arange(draw_batch_size),selection),norm_batchs_size,replace=False)\n",
    "    \n",
    "    selection = np.append(selection,selection2)\n",
    "    \n",
    "    triplets = [studybatch[0][selection,:,:,:], studybatch[1][selection,:,:,:], studybatch[2][selection,:,:,:]]\n",
    "    \n",
    "    return triplets\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "shapes i batch A: (2, 120, 120, 3) P:(2, 120, 120, 3) N :(2, 120, 120, 3)\n",
      "Shapes in the hardbatch A:(2, 120, 120, 3) P:(2, 120, 120, 3) N:(2, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "triplets=get_batch_random(2)\n",
    "print(len(triplets))\n",
    "print(\"shapes i batch A: {0} P:{1} N :{2}\".format(triplets[0].shape,triplets[1].shape,triplets[2].shape))\n",
    "\n",
    "hardtriplets=get_batch_hard(50,1,1,convnet)\n",
    "print(\"Shapes in the hardbatch A:{0} P:{1} N:{2}\".format(hardtriplets[0].shape, hardtriplets[1].shape, hardtriplets[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_every = 200  # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iteration = 15000        # No. of training iterations\n",
    "n_val = 200           # how many one-shot tasks to validate on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting traning process!\n",
      "--------------------------\n",
      "\n",
      " ------------- \n",
      "\n",
      "[15400] Time for 200 iterations: 8.5 mins, Train Loss: 10169.38671875\n"
     ]
    }
   ],
   "source": [
    "print(\"starting traning process!\")\n",
    "print(\"--------------------------\")\n",
    "t_start=time.time()\n",
    "dummy_target=[np.zeros((batch_size,15)) for i in range(3)]\n",
    "for i in range(1,n_iter+1):\n",
    "    triplets=get_batch_hard(200,16,16,convnet)\n",
    "    loss=model.train_on_batch(triplets,None)\n",
    "    n_iteration+=1\n",
    "    if i% evaluate_every==0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
